---
title: Do Outliers Ruin Collaboration?
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/qiao18a/qiao18a.pdf
url: http://proceedings.mlr.press/v80/qiao2018a.html
abstract: We consider the problem of learning a binary classifier from $n$ different
  data sources, among which at most an $η$ fraction are adversarial. The overhead
  is defined as the ratio between the sample complexity of learning in this setting
  and that of learning the same hypothesis class on a single data distribution. We
  present an algorithm that achieves an $O(ηn + \ln n)$ overhead, which is proved
  to be worst-case optimal. We also discuss the potential challenges to the design
  of a computationally efficient learning algorithm with a small overhead.
layout: inproceedings
id: qiao18a
tex_title: Do Outliers Ruin Collaboration?
firstpage: 4177
lastpage: 4184
page: 4177-4184
order: 4177
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Qiao, Mingda
author:
- given: Mingda
  family: Qiao
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
