---
title: 'Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent
  Converges Linearly for Phase Retrieval and Matrix Completion'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/ma18c/ma18c.pdf
url: http://proceedings.mlr.press/v80/ma2018c.html
abstract: 'Recent years have seen a flurry of activities in designing provably efficient
  nonconvex optimization procedures for solving statistical estimation problems. For
  various problems like phase retrieval or low-rank matrix completion, state-of-the-art
  nonconvex procedures require proper regularization (e.g. trimming, regularized cost,
  projection) in order to guarantee fastconvergence. When it comes to vanilla procedures
  such as gradient descent, however, prior theory either recommends highly conservative
  learning rates to avoid overshooting, or completely lacks performance guarantees.
  This paper uncovers a striking phenomenon in several nonconvex problems: even in
  the absence of explicit regularization, gradient descent follows a trajectory staying
  within a basin that enjoys nice geometry, consisting of points incoherent with the
  sampling mechanism. This “implicit regularization” feature allows gradient descent
  to proceed in a far more aggressive fashion without overshooting, which in turn
  results in substantial computational savings. Focusing on two statistical estimation
  problems, i.e. solving random quadratic systems of equations and low-rank matrix
  completion, we establish that gradient descent achieves near-optimal statistical
  and computational guarantees without explicit regularization. As a byproduct, for
  noisy matrix completion, we demonstrate that gradient descent enables optimal control
  of both entrywise and spectral-norm errors.'
layout: inproceedings
id: ma18c
tex_title: 'Implicit Regularization in Nonconvex Statistical Estimation: Gradient
  Descent Converges Linearly for Phase Retrieval and Matrix Completion'
firstpage: 3351
lastpage: 3360
page: 3351-3360
order: 3351
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Ma, Cong and Wang, Kaizheng and Chi, Yuejie and Chen, Yuxin
author:
- given: Cong
  family: Ma
- given: Kaizheng
  family: Wang
- given: Yuejie
  family: Chi
- given: Yuxin
  family: Chen
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/ma18c/ma18c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
