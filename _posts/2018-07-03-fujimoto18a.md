---
title: Addressing Function Approximation Error in Actor-Critic Methods
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf
url: http://proceedings.mlr.press/v80/fujimoto2018a.html
abstract: In value-based reinforcement learning methods such as deep Q-learning, function
  approximation errors are known to lead to overestimated value estimates and suboptimal
  policies. We show that this problem persists in an actor-critic setting and propose
  novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm
  builds on Double Q-learning, by taking the minimum value between a pair of critics
  to limit overestimation. We draw the connection between target networks and overestimation
  bias, and suggest delaying policy updates to reduce per-update error and further
  improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming
  the state of the art in every environment tested.
layout: inproceedings
id: fujimoto18a
tex_title: Addressing Function Approximation Error in Actor-Critic Methods
firstpage: 1582
lastpage: 1591
page: 1582-1591
order: 1582
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Fujimoto, Scott and van Hoof, Herke and Meger, David
author:
- given: Scott
  family: Fujimoto
- given: Herke
  family: Hoof
- given: David
  family: Meger
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
