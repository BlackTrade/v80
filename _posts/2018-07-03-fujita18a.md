---
title: Clipped Action Policy Gradient
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/fujita18a/fujita18a.pdf
url: http://proceedings.mlr.press/v80/fujita2018a.html
abstract: Many continuous control tasks have bounded action spaces. When policy gradient
  methods are applied to such tasks, out-of-bound actions need to be clipped before
  execution, while policies are usually optimized as if the actions are not clipped.
  We propose a policy gradient estimator that exploits the knowledge of actions being
  clipped to reduce the variance in estimation. We prove that our estimator, named
  clipped action policy gradient (CAPG), is unbiased and achieves lower variance than
  the conventional estimator that ignores action bounds. Experimental results demonstrate
  that CAPG generally outperforms the conventional estimator, indicating that it is
  a better policy gradient estimator for continuous control tasks. The source code
  is available at https://github.com/pfnet-research/capg.
layout: inproceedings
id: fujita18a
tex_title: Clipped Action Policy Gradient
firstpage: 1592
lastpage: 1601
page: 1592-1601
order: 1592
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Fujita, Yasuhiro and Maeda, Shin-ichi
author:
- given: Yasuhiro
  family: Fujita
- given: Shin-ichi
  family: Maeda
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/fujita18a/fujita18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
