---
title: Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit Structure
  in MDPs
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/zanette18a/zanette18a.pdf
url: http://proceedings.mlr.press/v80/zanette2018a.html
abstract: In order to make good decision under uncertainty an agent must learn from
  observations. To do so, two of the most common frameworks are Contextual Bandits
  and Markov Decision Processes (MDPs). In this paper, we study whether there exist
  algorithms for the more general framework (MDP) which automatically provide the
  best performance bounds for the specific problem at hand without user intervention
  and without modifying the algorithm. In particular, it is found that a very minor
  variant of a recently proposed reinforcement learning algorithm for MDPs already
  matches the best possible regret bound $\tilde O (\sqrt{SAT})$ in the dominant term
  if deployed on a tabular Contextual Bandit problem despite the agent being agnostic
  to such setting.
layout: inproceedings
id: zanette18a
tex_title: Problem Dependent Reinforcement Learning Bounds Which Can Identify Bandit
  Structure in {MDP}s
firstpage: 5747
lastpage: 5755
page: 5747-5755
order: 5747
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Zanette, Andrea and Brunskill, Emma
author:
- given: Andrea
  family: Zanette
- given: Emma
  family: Brunskill
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/zanette18a/zanette18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
