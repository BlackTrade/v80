---
title: "$D^2$: Decentralized Training over Decentralized Data"
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/tang18a/tang18a.pdf
url: http://proceedings.mlr.press/v80/tang2018a.html
abstract: 'While training a machine learning model using multiple workers, each of
  which collects data from its own data source, it would be useful when the data collected
  from different workers are <em>unique</em> and <em>different</em>. Ironically, recent
  analysis of decentralized parallel stochastic gradient descent (D-PSGD) relies on
  the assumption that the data hosted on different workers are <em>not too different</em>.
  In this paper, we ask the question: <em>Can we design a decentralized parallel stochastic
  gradient descent algorithm that is less sensitive to the data variance across workers?</em>
  In this paper, we present D$^2$, a novel decentralized parallel stochastic gradient
  descent algorithm designed for large data variance \xr{among workers} (imprecisely,
  “decentralized” data). The core of D$^2$ is a variance reduction extension of D-PSGD.
  It improves the convergence rate from $O\left({σ\over \sqrt{nT}} + {(nζ^2)^{\frac{1}{3}}
  \over T^{2/3}}\right)$ to $O\left({σ\over \sqrt{nT}}\right)$ where $ζ^{2}$ denotes
  the variance among data on different workers. As a result, D$^2$ is robust to data
  variance among workers. We empirically evaluated D$^2$ on image classification tasks,
  where each worker has access to only the data of a limited set of labels, and find
  that D$^2$ significantly outperforms D-PSGD.'
layout: inproceedings
id: tang18a
tex_title: "$D^2$: Decentralized Training over Decentralized Data"
firstpage: 4855
lastpage: 4863
page: 4855-4863
order: 4855
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Tang, Hanlin and Lian, Xiangru and Yan, Ming and Zhang, Ce and Liu,
  Ji
author:
- given: Hanlin
  family: Tang
- given: Xiangru
  family: Lian
- given: Ming
  family: Yan
- given: Ce
  family: Zhang
- given: Ji
  family: Liu
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/tang18a/tang18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
