---
title: 'Make the Minority Great Again: First-Order Regret Bound for Contextual Bandits'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/allen-zhu18b/allen-zhu18b.pdf
url: http://proceedings.mlr.press/v80/allen-zhu2018b.html
abstract: Regret bounds in online learning compare the playerâ€™s performance to $L*$,
  the optimal performance in hindsight with a fixed strategy. Typically such bounds
  scale with the square root of the time horizon $T$. The more refined concept of
  first-order regret bound replaces this with a scaling $\sqrt{L*}$, which may be
  much smaller than $\sqrt{T}$. It is well known that minor variants of standard algorithms
  satisfy first-order regret bounds in the full information and multi-armed bandit
  settings. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and
  Schapire raised the issue that existing techniques do not seem sufficient to obtain
  first-order regret bounds for the contextual bandit problem. In the present paper,
  we resolve this open problem by presenting a new strategy based on augmenting the
  policy space.
layout: inproceedings
id: allen-zhu18b
tex_title: 'Make the Minority Great Again: First-Order Regret Bound for Contextual
  Bandits'
firstpage: 186
lastpage: 194
page: 186-194
order: 186
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Allen-Zhu, Zeyuan and Bubeck, Sebastien and Li, Yuanzhi
author:
- given: Zeyuan
  family: Allen-Zhu
- given: Sebastien
  family: Bubeck
- given: Yuanzhi
  family: Li
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
