---
title: Learning to Act in Decentralized Partially Observable MDPs
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/dibangoye18a/dibangoye18a.pdf
url: http://proceedings.mlr.press/v80/dibangoye2018a.html
abstract: We address a long-standing open problem of reinforcement learning in decentralized
  partially observable Markov decision processes. Previous attempts focussed on different
  forms of generalized policy iteration, which at best led to local optima. In this
  paper, we restrict attention to plans, which are simpler to store and update than
  policies. We derive, under certain conditions, the first near-optimal cooperative
  multi-agent reinforcement learning algorithm. To achieve significant scalability
  gains, we replace the greedy maximization by mixed-integer linear programming. Experiments
  show our approach can learn to act near-optimally in many finite domains from the
  literature.
layout: inproceedings
id: dibangoye18a
tex_title: Learning to Act in Decentralized Partially Observable {MDP}s
firstpage: 1241
lastpage: 1250
page: 1241-1250
order: 1241
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Dibangoye, Jilles and Buffet, Olivier
author:
- given: Jilles
  family: Dibangoye
- given: Olivier
  family: Buffet
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/dibangoye18a/dibangoye18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
