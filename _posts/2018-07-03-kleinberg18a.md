---
title: 'An Alternative View: When Does SGD Escape Local Minima?'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/kleinberg18a/kleinberg18a.pdf
url: http://proceedings.mlr.press/v80/kleinberg2018a.html
abstract: Stochastic gradient descent (SGD) is widely used in machine learning. Although
  being commonly viewed as a fast but not accurate version of gradient descent (GD),
  it always finds better solutions than GD for modern neural networks. In order to
  understand this phenomenon, we take an alternative view that SGD is working on the
  convolved (thus smoothed) version of the loss function. We show that, even if the
  function $f$ has many bad local minima or saddle points, as long as for every point
  $x$, the weighted average of the gradients of its neighborhoods is one point convex
  with respect to the desired solution $x^*$, SGD will get close to, and then stay
  around $x^*$ with constant probability. Our result identifies a set of functions
  that SGD provably works, which is much larger than the set of convex functions.
  Empirically, we observe that the loss surface of neural networks enjoys nice one
  point convexity properties locally, therefore our theorem helps explain why SGD
  works so well for neural networks.
layout: inproceedings
id: kleinberg18a
tex_title: 'An Alternative View: When Does {SGD} Escape Local Minima?'
firstpage: 2698
lastpage: 2707
page: 2698-2707
order: 2698
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Kleinberg, Bobby and Li, Yuanzhi and Yuan, Yang
author:
- given: Bobby
  family: Kleinberg
- given: Yuanzhi
  family: Li
- given: Yang
  family: Yuan
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/kleinberg18a/kleinberg18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
