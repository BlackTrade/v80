---
title: 'Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/laurent18a/laurent18a.pdf
url: http://proceedings.mlr.press/v80/laurent2018a.html
abstract: 'We consider deep linear networks with arbitrary convex differentiable loss.
  We provide a short and elementary proof of the fact that all local minima are global
  minima if the hidden layers are either 1) at least as wide as the input layer, or
  2) at least as wide as the output layer. This result is the strongest possible in
  the following sense: If the loss is convex and Lipschitz but not differentiable
  then deep linear networks can have sub-optimal local minima.'
layout: inproceedings
id: laurent18a
tex_title: 'Deep Linear Networks with Arbitrary Loss: All Local Minima Are Global'
firstpage: 2902
lastpage: 2907
page: 2902-2907
order: 2902
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Laurent, Thomas and von Brecht, James
author:
- given: Thomas
  family: Laurent
- given: James
  family: Brecht
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
