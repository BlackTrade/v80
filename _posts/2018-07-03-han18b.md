---
title: Stein Variational Gradient Descent Without Gradient
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/han18b/han18b.pdf
url: http://proceedings.mlr.press/v80/han2018b.html
abstract: Stein variational gradient decent (SVGD) has been shown to be a powerful
  approximate inference algorithm for complex distributions. However, the standard
  SVGD requires calculating the gradient of the target density and cannot be applied
  when the gradient is unavailable. In this work, we develop a gradient-free variant
  of SVGD (GF-SVGD), which replaces the true gradient with a surrogate gradient, and
  corrects the introduced bias by re-weighting the gradients in a proper form. We
  show that our GF-SVGD can be viewed as the standard SVGD with a special choice of
  kernel, and hence directly inherits all the theoretical properties of SVGD. We shed
  insights on the empirical choice of the surrogate gradient and further, propose
  an annealed GF-SVGD that consistently outperforms a number of recent advanced gradient-free
  MCMC methods in our empirical studies.
layout: inproceedings
id: han18b
tex_title: Stein Variational Gradient Descent Without Gradient
firstpage: 1895
lastpage: 1903
page: 1895-1903
order: 1895
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Han, Jun and Liu, Qiang
author:
- given: Jun
  family: Han
- given: Qiang
  family: Liu
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/han18b/han18b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
