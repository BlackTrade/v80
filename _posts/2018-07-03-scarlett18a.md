---
title: Tight Regret Bounds for Bayesian Optimization in One Dimension
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/scarlett18a/scarlett18a.pdf
url: http://proceedings.mlr.press/v80/scarlett2018a.html
abstract: We consider the problem of Bayesian optimization (BO) in one dimension,
  under a Gaussian process prior and Gaussian sampling noise. We provide a theoretical
  analysis showing that, under fairly mild technical assumptions on the kernel, the
  best possible cumulative regret up to time $T$ behaves as $Ω(\sqrt{T})$ and $O(\sqrt{T\log
  T})$. This gives a tight characterization up to a $\sqrt{\log T}$ factor, and includes
  the first non-trivial lower bound for noisy BO. Our assumptions are satisfied, for
  example, by the squared exponential and Matérn-$ν$ kernels, with the latter requiring
  $ν> 2$. Our results certify the near-optimality of existing bounds (Srinivas <em>et
  al.</em>, 2009) for the SE kernel, while proving them to be strictly suboptimal
  for the Matérn kernel with $ν> 2$.
layout: inproceedings
id: scarlett18a
tex_title: Tight Regret Bounds for {B}ayesian Optimization in One Dimension
firstpage: 4507
lastpage: 4515
page: 4507-4515
order: 4507
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Scarlett, Jonathan
author:
- given: Jonathan
  family: Scarlett
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/scarlett18a/scarlett18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
