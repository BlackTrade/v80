---
title: 'Shampoo: Preconditioned Stochastic Tensor Optimization'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/gupta18a/gupta18a.pdf
url: http://proceedings.mlr.press/v80/gupta2018a.html
abstract: Preconditioned gradient methods are among the most general and powerful
  toolsin optimization. However, preconditioning requires storing and manipulatingprohibitively
  large matrices. We describe and analyze a new structure-awarepreconditioning algorithm,
  called Shampoo, for stochastic optimization overtensor spaces. Shampoo maintains
  a set of preconditioning matrices, each ofwhich operates on a single dimension,
  contracting over the remainingdimensions. We establish convergence guarantees in
  the stochastic convexsetting, the proof of which builds upon matrix trace inequalities.
  Ourexperiments with state-of-the-art deep learning models show that Shampoo iscapable
  of converging considerably faster than commonly used optimizers.Surprisingly, although
  it involves a more complex update rule, Shampooâ€™s runtime per step is comparable
  in practice to that of simple gradientmethods such as SGD, AdaGrad, and Adam.
layout: inproceedings
id: gupta18a
tex_title: 'Shampoo: Preconditioned Stochastic Tensor Optimization'
firstpage: 1837
lastpage: 1845
page: 1837-1845
order: 1837
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Gupta, Vineet and Koren, Tomer and Singer, Yoram
author:
- given: Vineet
  family: Gupta
- given: Tomer
  family: Koren
- given: Yoram
  family: Singer
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
