---
title: 'Shampoo: Preconditioned Stochastic Tensor Optimization'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/gupta18a/gupta18a.pdf
url: http://proceedings.mlr.press/v80/gupta2018a.html
abstract: Preconditioned gradient methods are among the most general and powerful
  tools in optimization. However, preconditioning requires storing and manipulating
  prohibitively large matrices. We describe and analyze a new structure-aware preconditioning
  algorithm, called Shampoo, for stochastic optimization over tensor spaces. Shampoo
  maintains a set of preconditioning matrices, each of which operates on a single
  dimension, contracting over the remaining dimensions. We establish convergence guarantees
  in the stochastic convex setting, the proof of which builds upon matrix trace inequalities.
  Our experiments with state-of-the-art deep learning models show that Shampoo is
  capable of converging considerably faster than commonly used optimizers. Surprisingly,
  although it involves a more complex update rule, Shampooâ€™s runtime per step is comparable
  in practice to that of simple gradient methods such as SGD, AdaGrad, and Adam.
layout: inproceedings
id: gupta18a
tex_title: 'Shampoo: Preconditioned Stochastic Tensor Optimization'
firstpage: 1842
lastpage: 1850
page: 1842-1850
order: 1842
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Gupta, Vineet and Koren, Tomer and Singer, Yoram
author:
- given: Vineet
  family: Gupta
- given: Tomer
  family: Koren
- given: Yoram
  family: Singer
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
