---
title: Stabilizing Gradients for Deep Neural Networks via Efficient SVD Parameterization
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/zhang18g/zhang18g.pdf
url: http://proceedings.mlr.press/v80/zhang2018g.html
abstract: Vanishing and exploding gradients are two of the main obstacles in training
  deep neural networks, especially in capturing long range dependencies in recurrent
  neural networks (RNNs). In this paper, we present an efficient parametrization of
  the transition matrix of an RNN that allows us to stabilize the gradients that arise
  in its training. Specifically, we parameterize the transition matrix by its singular
  value decomposition (SVD), which allows us to explicitly track and control its singular
  values. We attain efficiency by using tools that are common in numerical linear
  algebra, namely Householder reflectors for representing the orthogonal matrices
  that arise in the SVD. By explicitly controlling the singular values, our proposed
  Spectral-RNN method allows us to easily solve the exploding gradient problem and
  we observe that it empirically solves the vanishing gradient issue to a large extent.
  We note that the SVD parameterization can be used for any rectangular weight matrix,
  hence it can be easily extended to any deep neural network, such as a multi-layer
  perceptron. Theoretically, we demonstrate that our parameterization does not lose
  any expressive power, and show how it potentially makes the optimization process
  easier. Our extensive experimental results also demonstrate that the proposed framework
  converges faster, and has good generalization, especially in capturing long range
  dependencies, as shown on the synthetic addition and copy tasks, as well as on MNIST
  and Penn Tree Bank data sets.
layout: inproceedings
id: zhang18g
tex_title: Stabilizing Gradients for Deep Neural Networks via Efficient {SVD} Parameterization
firstpage: 5801
lastpage: 5809
page: 5801-5809
order: 5801
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Zhang, Jiong and Lei, Qi and Dhillon, Inderjit
author:
- given: Jiong
  family: Zhang
- given: Qi
  family: Lei
- given: Inderjit
  family: Dhillon
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/zhang18g/zhang18g-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
