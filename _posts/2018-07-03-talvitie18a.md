---
title: Learning the Reward Function for a Misspecified Model
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/talvitie18a/talvitie18a.pdf
url: http://proceedings.mlr.press/v80/talvitie2018a.html
abstract: In model-based reinforcement learning it is typical to decouple the problems
  of learning the dynamics model and learning the reward function. However, when the
  dynamics model is flawed, it may generate erroneous states that would never occur
  in the true environment. It is not clear a priori what value the reward function
  should assign to such states. This paper presents a novel error bound that accounts
  for the reward modelâ€™s behavior in states sampled from the model. This bound is
  used to extend the existing Hallucinated DAgger-MC algorithm, which offers theoretical
  performance guarantees in deterministic MDPs that do not assume a perfect model
  can be learned. Empirically, this approach to reward learning can yield dramatic
  improvements in control performance when the dynamics model is flawed.
layout: inproceedings
id: talvitie18a
tex_title: Learning the Reward Function for a Misspecified Model
firstpage: 4845
lastpage: 4854
page: 4845-4854
order: 4845
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Talvitie, Erik
author:
- given: Erik
  family: Talvitie
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/talvitie18a/talvitie18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
