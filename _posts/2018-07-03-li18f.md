---
title: The Well-Tempered Lasso
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/li18f/li18f.pdf
url: http://proceedings.mlr.press/v80/li2018f.html
abstract: We study the complexity of the entire regularization path for least squares
  regression with 1-norm penalty, known as the Lasso. Every regression parameter in
  the Lasso changes linearly as a function of the regularization value. The number
  of changes is regarded as the Lasso’s complexity. Experimental results using exact
  path following exhibit polynomial complexity of the Lasso in the problem size. Alas,
  the path complexity of the Lasso on artificially designed regression problems is
  exponential We use smoothed analysis as a mechanism for bridging the gap between
  worst case settings and the de facto low complexity. Our analysis assumes that the
  observed data has a tiny amount of intrinsic noise. We then prove that the Lasso’s
  complexity is polynomial in the problem size.
layout: inproceedings
id: li18f
tex_title: The Well-Tempered Lasso
firstpage: 3024
lastpage: 3032
page: 3024-3032
order: 3024
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Li, Yuanzhi and Singer, Yoram
author:
- given: Yuanzhi
  family: Li
- given: Yoram
  family: Singer
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
