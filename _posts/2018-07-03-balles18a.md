---
title: 'Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients'
booktitle: Proceedings of the 35th International Conference on Machine Learning
year: '2018'
volume: '80'
series: Proceedings of Machine Learning Research
address: 
month: 0
publisher: PMLR
pdf: http://proceedings.mlr.press/v80/balles18a/balles18a.pdf
url: http://proceedings.mlr.press/v80/balles2018a.html
abstract: 'The ADAM optimizer is exceedingly popular in the deep learning community.
  Often it works very well, sometimes it doesn’t. Why? We interpret ADAM as a combination
  of two aspects: for each weight, the update direction is determined by the sign
  of stochastic gradients, whereas the update magnitude is determined by an estimate
  of their relative variance. We disentangle these two aspects and analyze them in
  isolation, gaining insight into the mechanisms underlying ADAM. This analysis also
  extends recent results on adverse effects of ADAM on generalization, isolating the
  sign aspect as the problematic one. Transferring the variance adaptation to SGD
  gives rise to a novel method, completing the practitioner’s toolbox for problems
  where ADAM fails.'
layout: inproceedings
id: balles18a
tex_title: 'Dissecting Adam: The Sign, Magnitude and Variance of Stochastic Gradients'
firstpage: 413
lastpage: 422
page: 413-422
order: 413
cycles: false
bibtex_editor: Dy, Jennifer and Krause, Andreas
editor:
- given: Jennifer
  family: Dy
- given: Andreas
  family: Krause
bibtex_author: Balles, Lukas and Hennig, Philipp
author:
- given: Lukas
  family: Balles
- given: Philipp
  family: Hennig
date: 2018-07-03
container-title: Proceedings of the 35th International Conference on Machine Learning
genre: inproceedings
issued:
  date-parts:
  - 2018
  - 7
  - 3
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v80/balles18a/balles18a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
